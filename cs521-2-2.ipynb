{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe70a96",
   "metadata": {},
   "source": [
    "## Interval Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbda12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Normalize()\n",
       "  (1): Net(\n",
       "    (fc): Linear(in_features=784, out_features=200, bias=True)\n",
       "    (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorboardX\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "## Dataloaders\n",
    "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "## Simple NN. You can change this if you want. If you change it, mention the architectural details in your report.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = nn.Linear(28*28, 200)\n",
    "        self.fc2 = nn.Linear(200,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 28*28))\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.fc2(x)\n",
    "        # x = F.softmax(x, dim=-1) # added softmax for probabilities\n",
    "        return x\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return (x - 0.1307)/0.3081\n",
    "\n",
    "# Add the data normalization as a first \"layer\" to the network\n",
    "# this allows us to search for adverserial examples to the real image, rather than\n",
    "# to the normalized image\n",
    "model = nn.Sequential(Normalize(), Net())\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6282f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, num_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # tbar = tqdm(total=len(train_loader), desc=\"items of one epoch:\")\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        #     tbar.update(1)\n",
    "        # tbar.close()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.3f}')\n",
    "\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # tbar = tqdm(total=len(test_loader), desc=\"items of test:\")\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        #     tbar.update(1)\n",
    "        # tbar.close()\n",
    "        print(f'Accuracy on images: {100 * correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72dd8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:04<01:09,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:10<01:06,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Loss: 0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:15<01:02,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Loss: 0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:20<00:57,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Loss: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:25<00:52,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Loss: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:31<00:46,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Loss: 0.170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:36<00:41,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Loss: 0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:41<00:36,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Loss: 0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:46<00:31,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Loss: 0.130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:52<00:26,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Loss: 0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:57<00:21,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Loss: 0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [01:02<00:15,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Loss: 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [01:08<00:10,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Loss: 0.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [01:13<00:05,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Loss: 0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:18<00:00,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Loss: 0.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on images: 97.06\n"
     ]
    }
   ],
   "source": [
    "train_model(model, 15)\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c23f92",
   "metadata": {},
   "source": [
    "### Write the interval analysis for the simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97f7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Write the interval analysis for the simple model\n",
    "## you can use https://github.com/Zinoex/bound_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dec4d16-762a-48fa-94ad-4bb80a672f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
      "results:\n",
      "epsilon = 0.01, Accuracy: 31.93% = 3193/10000  \n",
      "epsilon = 0.02, Accuracy: 1.09% = 109/10000  \n",
      "epsilon = 0.03, Accuracy: 0.01% = 1/10000  \n",
      "epsilon = 0.04, Accuracy: 0.00% = 0/10000  \n",
      "epsilon = 0.05, Accuracy: 0.00% = 0/10000  \n",
      "epsilon = 0.06, Accuracy: 0.00% = 0/10000  \n",
      "epsilon = 0.07, Accuracy: 0.00% = 0/10000  \n",
      "epsilon = 0.08, Accuracy: 0.00% = 0/10000  \n",
      "epsilon = 0.09, Accuracy: 0.00% = 0/10000  \n",
      "epsilon = 0.10, Accuracy: 0.00% = 0/10000  \n"
     ]
    }
   ],
   "source": [
    "eps_list = [i/100 for i in list(range(1, 11))]\n",
    "verified_cnt_dict = dict.fromkeys(eps_list, 0)\n",
    "print(eps_list) # [0.01, ..., 0.10]\n",
    "\n",
    "def ibp_forward_normalize(lower, upper):    \n",
    "    lower = (lower - 0.1307) / 0.3081\n",
    "    upper = (upper - 0.1307) / 0.3081\n",
    "    return lower, upper\n",
    "\n",
    "def ibp_forward_relu(lower, upper):\n",
    "    # relu is like max(0,x)\n",
    "    lower = torch.clamp(lower, min=0)\n",
    "    upper = torch.clamp(upper, min=0)\n",
    "    return lower, upper\n",
    "\n",
    "def ibp_forward_linear(model, lower, upper):\n",
    "    # https://github.com/Zinoex/bound_propagation/blob/65bd7f80fd4133b16a0525db1ae008a7354bff8d/src/bound_propagation/linear.py#L69\n",
    "    center = (lower + upper) / 2\n",
    "    width = upper - lower\n",
    "    diff = width / 2\n",
    "    weight = model.weight\n",
    "    bias = model.bias\n",
    "    # https://github.com/Zinoex/bound_propagation/blob/65bd7f80fd4133b16a0525db1ae008a7354bff8d/src/bound_propagation/linear.py#L29\n",
    "    center, diff = center.unsqueeze(-2), diff.unsqueeze(-2)\n",
    "    weight = weight.transpose(-1, -2)\n",
    "\n",
    "    w_mid = center.matmul(weight)\n",
    "    if bias is not None:\n",
    "        w_mid = w_mid + bias.unsqueeze(-2)\n",
    "    w_diff = diff.matmul(weight.abs())\n",
    "\n",
    "    lower = w_mid - w_diff\n",
    "    lower = lower.squeeze(-2)\n",
    "\n",
    "    upper = w_mid + w_diff\n",
    "    upper = upper.squeeze(-2)\n",
    "\n",
    "    return lower, upper\n",
    "\n",
    "def ibp_forward_softmax(lower, upper):\n",
    "    lower_exp, upper_exp = torch.exp(lower), torch.exp(upper)\n",
    "    sum_lower_exp, sum_upper_exp = lower_exp.sum(dim=-1, keepdim=True) , upper_exp.sum(dim=-1, keepdim=True)\n",
    "    lower_softmax = lower_exp / sum_upper_exp\n",
    "    upper_softmax = upper_exp / sum_lower_exp\n",
    "    return lower_softmax, upper_softmax\n",
    "\n",
    "def ibp(model, lower, upper):\n",
    "    # We have 3 types of layers in the model here!\n",
    "    \n",
    "    # Linear\n",
    "    # https://github.com/Zinoex/bound_propagation/blob/65bd7f80fd4133b16a0525db1ae008a7354bff8d/src/bound_propagation/linear.py#L67\n",
    "\n",
    "    # Activation\n",
    "    # https://github.com/Zinoex/bound_propagation/blob/65bd7f80fd4133b16a0525db1ae008a7354bff8d/src/bound_propagation/activation.py#L120\n",
    "\n",
    "    # Normalization\n",
    "    \n",
    "    for layer in model:\n",
    "        if isinstance(layer, Normalize): # as its the first layer\n",
    "            lower, upper = ibp_forward_normalize(lower, upper)\n",
    "        elif isinstance(layer, Net):\n",
    "            # propagate through each layer now\n",
    "            lower, upper = ibp_forward_linear(layer.fc, lower, upper)\n",
    "            lower, upper = ibp_forward_relu(lower, upper)\n",
    "            lower, upper = ibp_forward_linear(layer.fc2, lower, upper)\n",
    "            # lower, upper = ibp_forward_softmax(lower, upper)\n",
    "    return lower, upper\n",
    "\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    x = images.view(images.size(0), -1) # 64, 784\n",
    "    for eps in eps_list:\n",
    "        #hyper rectangle for the batch of data\n",
    "        #https://github.com/Zinoex/bound_propagation/blob/65bd7f80fd4133b16a0525db1ae008a7354bff8d/src/bound_propagation/bounds.py#L160\n",
    "        # lower = x - eps\n",
    "        lower = torch.clamp(x-eps, 0.0, 1.0)\n",
    "        # upper = x + eps\n",
    "        upper = torch.clamp(x+eps, 0.0, 1.0)\n",
    "        lower_final, upper_final = ibp(model, lower, upper)\n",
    "        batch_size = x.size(0)\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i].item()\n",
    "            flag = True\n",
    "            for j in range(10): # 10 classes 0 - 9 \n",
    "                if lower_final[i, label] <= upper_final[i, j] and j != label:\n",
    "                    flag = False; break\n",
    "            if flag:\n",
    "                verified_cnt_dict[eps] += 1\n",
    "\n",
    "print(\"results:\")\n",
    "for eps in eps_list:\n",
    "    acc = 100 * verified_cnt_dict[eps] / len(test_dataset)\n",
    "    print(f\"epsilon = {eps:.2f}, Accuracy: {acc:.2f}% = {verified_cnt_dict[eps]}/{len(test_dataset)}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d51bdb9-fed8-4f9a-9660-951182082bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158f22f-180e-41a7-8630-3a082b495afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
