{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7308aa-a2ff-4f8e-aec3-2f86a84b70d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c151a7cd-c5d2-48dd-84cf-3d801fbbb73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 41.0MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.11MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 11.6MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.72MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Normalize()\n",
       "  (1): Net(\n",
       "    (fc1): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (fc3): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (out): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "## Dataloaders\n",
    "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "## Simple NN. You can change this if you want. If you change it, mention the architectural details in your report.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 50)\n",
    "        self.out = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 28*28))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.out(x) # logits out!\n",
    "        return x\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return (x - 0.1307)/0.3081\n",
    "\n",
    "# Add the data normalization as a first \"layer\" to the network\n",
    "# this allows us to search for adverserial examples to the real image, rather than\n",
    "# to the normalized image\n",
    "model = nn.Sequential(Normalize(), Net())\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ae0098-284f-4633-b4c7-f8aec56e75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_linf_untargeted(model, x, labels, k, eps, eps_step):\n",
    "    # model.eval()\n",
    "    ce_loss = torch.nn.CrossEntropyLoss()\n",
    "    adv_x = x.clone().detach()\n",
    "    adv_x.requires_grad_(True) \n",
    "    for _ in range(k):\n",
    "        adv_x.requires_grad_(True)\n",
    "        model.zero_grad()\n",
    "        output = model(adv_x)\n",
    "        # TODO: Calculate the loss\n",
    "        loss = ce_loss(output, labels)\n",
    "        loss.backward()\n",
    "        # TODO: compute the adv_x\n",
    "        # find delta, clamp with eps          \n",
    "        delta = torch.clamp(adv_x + eps_step * adv_x.grad.sign() - x.data, min=-eps, max=eps)\n",
    "        adv_x = torch.clamp(x.data + delta, min=0, max=1).detach_()\n",
    "   \n",
    "    return adv_x\n",
    "\n",
    "def pgd_l2_untargeted(model, x, labels, k, eps, eps_step):\n",
    "    # model.eval()\n",
    "    ce_loss = torch.nn.CrossEntropyLoss()\n",
    "    adv_x = x.clone().detach()\n",
    "    adv_x.requires_grad_(True) \n",
    "    for _ in range(k):\n",
    "        adv_x.requires_grad_(True)\n",
    "        model.zero_grad()\n",
    "        output = model(adv_x)\n",
    "        batch_size = x.size()[0]\n",
    "        # TODO: Calculate the loss\n",
    "        loss = ce_loss(output, labels)\n",
    "        loss.backward()\n",
    "        grad = adv_x.grad.data\n",
    "        # TODO: compute the adv_x\n",
    "        # find delta, clamp with eps, project delta to the l2 ball\n",
    "        # HINT: https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/torchattacks/attacks/pgdl2.py\n",
    "        eps_for_division = 1e-10\n",
    "        grad_norms = (\n",
    "            torch.norm(grad.view(batch_size, -1), p=2, dim=1)\n",
    "            + eps_for_division\n",
    "        )  # nopep8\n",
    "        grad = grad / grad_norms.view(batch_size, 1, 1, 1)\n",
    "        adv_x = adv_x.detach() + eps_step * grad\n",
    "        \n",
    "        delta = adv_x  - x.data\n",
    "        delta_norms = torch.norm(delta.view(batch_size, -1), p=2, dim=1)\n",
    "        factor = eps / delta_norms\n",
    "        factor = torch.min(factor, torch.ones_like(delta_norms))\n",
    "        delta = delta * factor.view(-1, 1, 1, 1)\n",
    "        \n",
    "        adv_x = torch.clamp(x.data + delta, min=0, max=1).detach_()\n",
    "   \n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6320a7f9-46c3-4266-b8b0-02e087e55f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # tbar = tqdm(total=len(test_loader), desc=\"items of test:\")\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        #     tbar.update(1)\n",
    "        # tbar.close()\n",
    "        print(f'Accuracy on images: {100 * correct / total}')\n",
    "\n",
    "def test_model_robust(model, attack='pgd', eps=8/255, k=10):\n",
    "    model.eval()\n",
    "    # with torch.no_grad():abs\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # tbar = tqdm(total=len(test_loader), desc=\"items of test:\")\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        if attack == 'fgsm':\n",
    "            adv_images = pgd_linf_untargeted(model, images, labels, k=1, eps=eps, eps_step=eps)\n",
    "        else:  # pgd\n",
    "            adv_images = pgd_linf_untargeted(model, images, labels, k=k, eps=eps, eps_step=eps/4)\n",
    "        outputs = model(adv_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    #     tbar.update(1)\n",
    "    # tbar.close()\n",
    "    print(f'Accuracy on images: {100 * correct / total}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5071769-1ab2-4543-bba2-f84d6f72d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model_ibp(model, num_epochs, eps_target=0.1, k_start=1.0, k_end=0.5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # gradual schedules for k and eps\n",
    "        k = k_start + (k_end - k_start) * (epoch / max(num_epochs - 1, 1))\n",
    "        eps_train = eps_target * (epoch / max(num_epochs - 1, 1))\n",
    "\n",
    "        # tbar = tqdm(total=len(train_loader), desc=\"items of one epoch:\")\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            print(f\"{i}/{len(train_loader)}\", end=\"\\r\")\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(images)\n",
    "            l = torch.clamp(images - eps_train, 0.0, 1.0)\n",
    "            u = torch.clamp(images + eps_train, 0.0, 1.0)\n",
    "            l = (l - 0.1307) / 0.3081\n",
    "            u = (u - 0.1307) / 0.3081\n",
    "            B = images.size(0)\n",
    "            l = l.view(B, -1)\n",
    "            u = u.view(B, -1)\n",
    "            net = model[1]\n",
    "\n",
    "            # fc1 relu\n",
    "            W, b = net.fc1.weight, net.fc1.bias\n",
    "            Wp, Wn = torch.clamp(W, min=0), torch.clamp(W, max=0)\n",
    "            lo = l @ Wp.t() + u @ Wn.t() + b\n",
    "            hi = u @ Wp.t() + l @ Wn.t() + b\n",
    "            l, u = F.relu(lo), F.relu(hi)\n",
    "\n",
    "            # fc2 relu\n",
    "            W, b = net.fc2.weight, net.fc2.bias\n",
    "            Wp, Wn = torch.clamp(W, min=0), torch.clamp(W, max=0)\n",
    "            lo = l @ Wp.t() + u @ Wn.t() + b\n",
    "            hi = u @ Wp.t() + l @ Wn.t() + b\n",
    "            l, u = F.relu(lo), F.relu(hi)\n",
    "\n",
    "            # fc3 relu\n",
    "            W, b = net.fc3.weight, net.fc3.bias\n",
    "            Wp, Wn = torch.clamp(W, min=0), torch.clamp(W, max=0)\n",
    "            lo = l @ Wp.t() + u @ Wn.t() + b\n",
    "            hi = u @ Wp.t() + l @ Wn.t() + b\n",
    "            l, u = F.relu(lo), F.relu(hi)\n",
    "\n",
    "            # out layer (logits)\n",
    "            W, b = net.out.weight, net.out.bias\n",
    "            Wp, Wn = torch.clamp(W, min=0), torch.clamp(W, max=0)\n",
    "            lo = l @ Wp.t() + u @ Wn.t() + b\n",
    "            hi = u @ Wp.t() + l @ Wn.t() + b\n",
    "            l, u = lo, hi\n",
    "\n",
    "            # pessimistic logits\n",
    "            logits_hat = u.clone()\n",
    "            idx = torch.arange(labels.size(0), device=labels.device)\n",
    "            logits_hat[idx, labels] = l[idx, labels]\n",
    "            loss = k * criterion(outputs, labels) + (1.0 - k) * criterion(logits_hat, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        #     tbar.update(1)\n",
    "        # tbar.close()\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, k={k:.3f}, eps_train={eps_train:.3f}, Loss: {running_loss/len(train_loader):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89dde4c-4e7e-4aa8-9865-28749a2fbae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/938\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [04:15<38:16, 255.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, k=1.000, eps_train=0.000, Loss: 0.452\n",
      "937/938\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [08:35<34:26, 258.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, k=0.944, eps_train=0.011, Loss: 0.269\n",
      "937/938\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [12:46<29:43, 254.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, k=0.889, eps_train=0.022, Loss: 0.235\n",
      "937/938\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [17:06<25:41, 256.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, k=0.833, eps_train=0.033, Loss: 0.257\n",
      "936/938\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [21:47<22:08, 265.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, k=0.778, eps_train=0.044, Loss: 0.293\n",
      "936/938\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [26:51<18:34, 278.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, k=0.722, eps_train=0.056, Loss: 0.336\n",
      "50/938\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [27:06<18:04, 271.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(Normalize(), Net())\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model_ibp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 69\u001b[0m, in \u001b[0;36mtrain_model_ibp\u001b[0;34m(model, num_epochs, eps_target, k_start, k_end)\u001b[0m\n\u001b[1;32m     66\u001b[0m logits_hat[idx, labels] \u001b[38;5;241m=\u001b[39m l[idx, labels]\n\u001b[1;32m     67\u001b[0m loss \u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m*\u001b[39m criterion(outputs, labels) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m k) \u001b[38;5;241m*\u001b[39m criterion(logits_hat, labels)\n\u001b[0;32m---> 69\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     72\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(Normalize(), Net()).to(device)\n",
    "train_model_ibp(model, num_epochs=5, eps_target=0.1, k_start=1.0, k_end=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f3dfb0-bcc3-4f49-a852-6145c450b067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing adversarily trained model acuracy:\n",
      "Accuracy on images: 95.87\n",
      "Testing adversarily trained model robustness, eps 0:\n",
      "Accuracy on images: 95.87\n",
      "Testing adversarily trained model robustness, eps 0.00392156862745098:\n",
      "Accuracy on images: 95.54\n",
      "Testing adversarily trained model robustness, eps 0.00784313725490196:\n",
      "Accuracy on images: 95.26\n",
      "Testing adversarily trained model robustness, eps 0.01568627450980392:\n",
      "Accuracy on images: 94.45\n",
      "Testing adversarily trained model robustness, eps 0.03137254901960784:\n",
      "Accuracy on images: 92.69\n",
      "Testing adversarily trained model robustness, eps 0.06274509803921569:\n",
      "Accuracy on images: 87.68\n",
      "Testing adversarily trained model robustness, eps 0.12549019607843137:\n",
      "Accuracy on images: 66.38\n",
      "Testing adversarily FGSM, eps 0:\n",
      "Accuracy on images: 95.87\n",
      "Testing adversarily FGSM, eps 0.00392156862745098:\n",
      "Accuracy on images: 95.83\n",
      "Testing adversarily FGSM, eps 0.00784313725490196:\n",
      "Accuracy on images: 95.76\n",
      "Testing adversarily FGSM, eps 0.01568627450980392:\n",
      "Accuracy on images: 95.54\n",
      "Testing adversarily FGSM, eps 0.03137254901960784:\n",
      "Accuracy on images: 95.28\n",
      "Testing adversarily FGSM, eps 0.06274509803921569:\n",
      "Accuracy on images: 94.53\n",
      "Testing adversarily FGSM, eps 0.12549019607843137:\n",
      "Accuracy on images: 92.89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epsilon_values = [0, 1/255, 2/255, 4/255, 8/255, 16/255, 32/255]\n",
    "\n",
    "\n",
    "print(\"Testing adversarily trained model acuracy:\")\n",
    "test_model(model)\n",
    "\n",
    "for eps in epsilon_values:\n",
    "    print(f\"Testing adversarily trained model robustness, eps {eps}:\")\n",
    "    test_model_robust(model, attack='pgd', eps=eps, k=10)\n",
    "\n",
    "for eps in epsilon_values:\n",
    "    print(f\"Testing adversarily FGSM, eps {eps}:\")\n",
    "    test_model_robust(model, attack='pgd', eps=eps, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a89c66a-2697-481f-872c-7c61a86fdafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853c5c6-a9b3-4d4e-a1a0-a6ccf67c3d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
